{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda config --add channels conda-forge\n",
    "!conda install -y libsndfile\n",
    "!conda install pywt \n",
    "!conda install soundfile \n",
    "!conda install librosa "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import types\n",
    "import ibm_boto3\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "from botocore.client import Config\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "\n",
    "import pywt\n",
    "\n",
    "    \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __iter__(self): return 0\n",
    "\n",
    "#\n",
    "# INSERT YOUR CONNECTION TO audio_data.zip HERE\n",
    "# USE Insert StreamingBody object\n",
    "#\n",
    "\n",
    "data_bytes = BytesIO(streaming_body_1.read())\n",
    "zip_file = ZipFile(data_bytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data used for this demonstration comes from the Urban Sounds Dataset. This dataset and its taxonomy is presented in J. Salamon, C. Jacoby and J. P. Bello, A Dataset and Taxonomy for Urban Sound Research, 22nd ACM International Conference on Multimedia, Orlando USA, Nov. 2014.\n",
    "\n",
    "For simplicity the dataset is sampled and a subset of 20 audio clips from two categories are used - air conditioner (AC) and drill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZipFile.namelist(zip_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_data = []\n",
    "labels = []\n",
    "sampling_rate = []\n",
    "file_names = []\n",
    "\n",
    "for file_name in ZipFile.namelist(zip_file):\n",
    "    # Skip directories\n",
    "    if not os.path.basename(file_name):\n",
    "        continue\n",
    "    \n",
    "    audio_file = None\n",
    "    if file_name.startswith(\"audio_data/ac/\"):\n",
    "        labels.append(0)\n",
    "        audio_file = zip_file.open(file_name)\n",
    "    elif file_name.startswith(\"audio_data/drill/\"):\n",
    "        labels.append(1)\n",
    "        audio_file = zip_file.open(file_name)\n",
    "    else:\n",
    "        print(\"Unknown file class. Skipping.\")\n",
    "\n",
    "    if audio_file is not None:\n",
    "        file_names.append(file_name)\n",
    "        tmp = BytesIO(audio_file.read())\n",
    "        data, samplerate = sf.read(tmp)\n",
    "        audio_data.append(data)\n",
    "        sampling_rate.append(samplerate)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(len(audio_data)):\n",
    "    \n",
    "    if (sampling_rate[index] == 48000):\n",
    "        audio_data[index] = librosa.resample(audio_data[index], 48000, 44100)\n",
    "        sampling_rate[index] = 44100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_mono(data):\n",
    "    if data.ndim > 1:\n",
    "        data = np.mean(data, axis=1)\n",
    "    return data\n",
    "\n",
    "for index in range(len(audio_data)):\n",
    "    audio_data[index] = to_mono(audio_data[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14,6))\n",
    "plt.plot(audio_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14,6))\n",
    "plt.plot(audio_data[21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = np.arange(1, 101)\n",
    "coeff1, freqs1 = pywt.cwt(audio_data[1][:25000], scales, 'morl')\n",
    "coeff2, freqs2 = pywt.cwt(audio_data[21][:25000], scales, 'morl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(20,10))\n",
    "plt.subplot(121)\n",
    "plt.imshow(coeff1, cmap='coolwarm', aspect='auto')  \n",
    "plt.subplot(122)\n",
    "plt.imshow(coeff2, cmap='coolwarm', aspect='auto')  \n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "\n",
    "fig = plt.figure(figsize=(40,15))\n",
    "\n",
    "ax1 = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "\n",
    "Y = np.arange(1, 101, 1)\n",
    "X = np.arange(1, 25001, 1)\n",
    "\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "\n",
    "ax1.plot_surface(X, Y, coeff1, cmap=cm.coolwarm, linewidth=0, antialiased=True)\n",
    "\n",
    "ax1.set_xlabel(\"Time\", fontsize=20)\n",
    "ax1.set_ylabel(\"Scale\", fontsize=20)\n",
    "ax1.set_zlabel(\"Amplitude\", fontsize=20)\n",
    "ax1.set_zlim3d(-1,1)\n",
    "\n",
    "ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "\n",
    "ax2.plot_surface(X, Y, coeff2, cmap=cm.coolwarm, linewidth=0, antialiased=True)\n",
    "\n",
    "\n",
    "ax2.set_xlabel(\"Time\", fontsize=20)\n",
    "ax2.set_ylabel(\"Scale\", fontsize=20)\n",
    "ax2.set_zlabel(\"Amplitude\", fontsize=20)\n",
    "ax2.set_zlim3d(-1,1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=1)\n",
    "\n",
    "features = np.empty((0,100))\n",
    "\n",
    "for ind in range(len(audio_data)):\n",
    "    print('.', end='')\n",
    "    coeff, freqs = pywt.cwt(audio_data[ind][:25000], scales, 'morl')    \n",
    "    features = np.vstack([features, pca.fit_transform(coeff).flatten()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.20, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy : %.2f%%\" % (accuracy_score(y_test, y_pred) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
