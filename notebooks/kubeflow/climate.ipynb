{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kfp kfp-tekton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp.components import create_component_from_func\n",
    "from kfp_tekton.compiler import TektonCompiler\n",
    "import kfp.dsl as dsl\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add():\n",
    "  return\n",
    "\n",
    "\n",
    "def create_comp(f):\n",
    "  return create_component_from_func(\n",
    "    f, output_component_file=f'{f.__name__}_component.yaml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_geodn_discovery():\n",
    "    return\n",
    "\n",
    "def regrid():\n",
    "    return\n",
    "\n",
    "def join_spatial():\n",
    "    return\n",
    "\n",
    "t_join_spatial = create_comp(join_spatial)\n",
    "\n",
    "\n",
    "def join_spatio_temporal():\n",
    "    return\n",
    "\n",
    "def mask_clouds():\n",
    "    return\n",
    "\n",
    "def normalize():\n",
    "    return\n",
    "\n",
    "def prithvi_finetune():\n",
    "    return\n",
    "\n",
    "def test():\n",
    "    return\n",
    "\n",
    "def deploy_model_mesh():\n",
    "    return\n",
    "\n",
    "def postgis_connector():\n",
    "    return\n",
    "\n",
    "t_postgis_connector = create_comp(postgis_connector)\n",
    "\n",
    "def generate_annotations():\n",
    "    return\n",
    "\n",
    "t_generate_annotations = create_comp(generate_annotations)\n",
    "\n",
    "\n",
    "\n",
    "a = create_comp(query_geodn_discovery)\n",
    "b = create_comp(regrid)\n",
    "c = create_comp(query_geodn_discovery)\n",
    "d = create_comp(regrid)\n",
    "e = create_comp(join_spatio_temporal)\n",
    "f = create_comp(mask_clouds)\n",
    "g = create_comp(normalize)\n",
    "h = create_comp(prithvi_finetune)\n",
    "i = create_comp(test)\n",
    "j = create_comp(deploy_model_mesh)\n",
    "\n",
    "\n",
    "def train_test_split():\n",
    "    return\n",
    "\n",
    "t_train_test_split = create_comp(train_test_split)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "  name='Addition pipeline',\n",
    "  description='An example pipeline that performs addition calculations.'\n",
    ")\n",
    "def add_pipeline():\n",
    "  bb = b()\n",
    "  bb.after(a())\n",
    "  dd = d()\n",
    "  dd.after(c())\n",
    "  ee = e()\n",
    "  ee.after(bb, dd)\n",
    "\n",
    "  f_postgis_connector = t_postgis_connector()\n",
    "\n",
    "  f_generate_annotations = t_generate_annotations()\n",
    "\n",
    "  f_generate_annotations.after(f_postgis_connector)\n",
    "\n",
    "\n",
    "  f_join_spatial = t_join_spatial()\n",
    "\n",
    "  f_join_spatial.after(ee,f_generate_annotations)\n",
    "\n",
    "\n",
    "  gg = g().after(f().after(f_join_spatial))\n",
    "\n",
    "  f_train_test_split = t_train_test_split()\n",
    "\n",
    "  f_train_test_split.after(gg)\n",
    "\n",
    "  hh = h()\n",
    "\n",
    "  j().after(i().after(f_train_test_split, hh.after(f_train_test_split)))\n",
    "\n",
    "\n",
    "# Create a pipeline run, using the client you initialized in a prior step.\n",
    "TektonCompiler().compile(add_pipeline, 'climate.yaml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp.components as comp\n",
    " \n",
    "#volume_op = comp.load_component_from_url('https://raw.githubusercontent.com/kubeflow/pipelines/master/components/kubernetes/volume/component.yaml')\n",
    "#input_url = comp.load_component_from_url('https://raw.githubusercontent.com/romeokienzler/component-library/main/component-library/input/input-url.yaml')\n",
    "input_url = comp.load_component_from_file('/home/romeokienzler/gitco/component-library/component-library/input/input-url.yaml')\n",
    "#upload_to_cos = comp.load_component_from_url('https://raw.githubusercontent.com/romeokienzler/component-library/main/component-library/output/upload-to-cos.yaml')\n",
    "upload_to_cos = comp.load_component_from_file('/home/romeokienzler/gitco/component-library/component-library/output/upload-to-cos.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp.dsl as dsl\n",
    "import kfp\n",
    "from kfp_tekton.compiler import TektonCompiler\n",
    "\n",
    "# Define your pipeline function\n",
    "@dsl.pipeline(\n",
    "    name=\"My Pipeline\",\n",
    "    description=\"A sample Kubeflow pipeline\"\n",
    ")\n",
    "def my_pipeline():\n",
    "    step1 = input_url(\n",
    "            url='https://github.com/claimed-framework/component-library/raw/main/hmp.parquet',\n",
    "            data_dir='.'\n",
    "    )\n",
    "\n",
    "    step2 = upload_to_cos(\n",
    "        access_key_id='adbb855da5004670b679dcf5d0fc3028',\n",
    "        secret_access_key='a7a94d0029fa2f44827a5b5da1ad0693c4ed87a843f6ea30',\n",
    "        endpoint='https://s3.us-east.cloud-object-storage.appdomain.cloud',\n",
    "        bucket_name='era5-cropscape-zarr',\n",
    "        source_file=step1.output,\n",
    "        destination_file='hmp.parquet',\n",
    "        data_dir=''\n",
    "    )\n",
    "\n",
    "\n",
    "    pvc_mount_path = '/data'\n",
    "    pvc_name = 'kfp-data-pvc'\n",
    "\n",
    "    # Create a PipelineVolume to mount the PVC\n",
    "    pipeline_volume = dsl.PipelineVolume(pvc_name)\n",
    "\n",
    "    # Connect the steps with the mounted PVC\n",
    "    step1.add_pvolumes({pvc_mount_path: pipeline_volume})\n",
    "    step2.add_pvolumes({pvc_mount_path: pipeline_volume})\n",
    "    \n",
    "    step2.after(step1)\n",
    "\n",
    "# Compile the pipeline\n",
    "pipeline_func = my_pipeline\n",
    "TektonCompiler().compile(pipeline_func, 'FirstPipeline.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
