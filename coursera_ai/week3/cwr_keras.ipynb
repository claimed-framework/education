{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation steps before running this notebook\n",
    "1. Run cwr_etl.ipynb first\n",
    "2. Paste the IBM COS (Cloud Object Store) configuration below, either bei following the tutorial mentioned below or by taking the already existing config from cwr_etl.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow==2.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to obtain the correct values for \"credentias\", \"bucket_name\" and \"endpoint\" \n",
    "# please follow the tutorial at https://github.com/IBM/skillsnetwork/wiki/Cloud-Object-Storage-Setup\n",
    "\n",
    "credentials = {\n",
    "  # your credentials go here\n",
    "}\n",
    "\n",
    "\n",
    "bucket_name = # your bucket name goes here\n",
    "endpoint = # your endpoint goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from ibm_botocore.client import Config\n",
    "import ibm_boto3\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create client \n",
    "client = ibm_boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id = credentials[\"cos_hmac_keys\"]['access_key_id'],\n",
    "    aws_secret_access_key = credentials[\"cos_hmac_keys\"][\"secret_access_key\"],\n",
    "    endpoint_url=endpoint\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "client.download_file(bucket_name,'result_healthy_pandas.csv', 'result_healthy_pandas.csv')\n",
    "client.download_file(bucket_name,'result_faulty_pandas.csv', 'result_faulty_pandas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_healthy = pd.read_csv('result_healthy_pandas.csv', engine='python', header=None)\n",
    "df_healthy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_healthy.loc[df_healthy[1] == 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_faulty = pd.read_csv('result_faulty_pandas.csv', engine='python', header=None)\n",
    "df_faulty.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "import sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import Callback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Activation\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recording(df,file_id):\n",
    "    return np.array(df.sort_values(by=0, ascending=True).loc[df[1] == file_id].drop(0,1).drop(1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "healthy_sample = get_recording(df_healthy,100)\n",
    "faulty_sample = get_recording(df_faulty,105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(num=None, figsize=(14, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "size = len(healthy_sample)\n",
    "ax.plot(range(0,size), healthy_sample[:,0], '-', color='red', animated = True, linewidth=1)\n",
    "ax.plot(range(0,size), healthy_sample[:,1], '-', color='blue', animated = True, linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(num=None, figsize=(14, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "size = len(faulty_sample)\n",
    "ax.plot(range(0,size), faulty_sample[:,1], '-', color='red', animated = True, linewidth=1)\n",
    "ax.plot(range(0,size), faulty_sample[:,0], '-', color='blue', animated = True, linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(num=None, figsize=(14, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "ax.plot(range(0,500), healthy_sample[:500,0], '-', color='red', animated = True, linewidth=1)\n",
    "ax.plot(range(0,500), healthy_sample[:500,1], '-', color='blue', animated = True, linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(num=None, figsize=(14, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "ax.plot(range(0,500), faulty_sample[:500,0], '-', color='red', animated = True, linewidth=1)\n",
    "ax.plot(range(0,500), faulty_sample[:500,1], '-', color='blue', animated = True, linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 100\n",
    "dim = 2\n",
    "lossHistory = LossHistory()\n",
    "# design network\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(50,input_shape=(timesteps,dim),return_sequences=True))\n",
    "model.add(Dense(2))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "\n",
    "def train(data):\n",
    "    model.fit(data, data, epochs=20, batch_size=72, validation_data=(data, data), verbose=1, shuffle=False,callbacks=[lossHistory])\n",
    "\n",
    "def score(data):\n",
    "    yhat =  model.predict(data)\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some learners constantly reported 502 errors in Watson Studio. \n",
    "#This is due to the limited resources in the free tier and the heavy resource consumption of Keras.\n",
    "#This is a workaround to limit resource consumption\n",
    "\n",
    "import os\n",
    "# reduce number of threads\n",
    "os.environ['TF_NUM_INTEROP_THREADS'] = '1'\n",
    "os.environ['TF_NUM_INTRAOP_THREADS'] = '1'\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trimmed_recording(df,file_id):\n",
    "    recording = get_recording(df,file_id) \n",
    "    samples = len(recording)\n",
    "    trim = samples % 100\n",
    "    recording_trimmed = recording[:samples-trim]\n",
    "    recording_trimmed.shape = (int((samples-trim)/timesteps),timesteps,dim)\n",
    "    return recording_trimmed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.unique()\n",
    "#df_healthy.drop(0,1).drop(2,1).drop(3,1)\n",
    "pd.unique(df_healthy.iloc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ids = pd.unique(df_healthy.iloc[:,1])\n",
    "start = time.time()\n",
    "for file_id in file_ids:\n",
    "    recording_trimmed = create_trimmed_recording(df_healthy,file_id)\n",
    "    print(\"Staring training on %s\" % (file_id))\n",
    "    train(recording_trimmed)\n",
    "    print(\"Finished training on %s after %s seconds\" % (file_id,time.time()-start))\n",
    "\n",
    "print(\"Finished job on after %s seconds\" % (time.time()-start))\n",
    "healthy_losses = lossHistory.losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(num=None, figsize=(14, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "size = len(healthy_losses)\n",
    "plt.ylim(0,0.008)\n",
    "ax.plot(range(0,size), healthy_losses, '-', color='blue', animated = True, linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_ids = spark.sql('select distinct _c1 from df_healhty').rdd.map(lambda row : row._c1).collect()\n",
    "start = time.time()\n",
    "for file_id in [105]:\n",
    "    recording_trimmed = create_trimmed_recording(df_faulty,file_id)\n",
    "    print(\"Staring training on %s\" % (file_id))\n",
    "    train(recording_trimmed)\n",
    "    print(\"Finished training on %s after %s seconds\" % (file_id,time.time()-start))\n",
    "\n",
    "print(\"Finished job on after %s seconds\" % (time.time()-start))\n",
    "faulty_losses = lossHistory.losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ids = pd.unique(df_faulty.iloc[:,1])\n",
    "start = time.time()\n",
    "for file_id in file_ids:\n",
    "    recording_trimmed = create_trimmed_recording(df_faulty,file_id)\n",
    "    print(\"Staring training on %s\" % (file_id))\n",
    "    train(recording_trimmed)\n",
    "    print(\"Finished training on %s after %s seconds\" % (file_id,time.time()-start))\n",
    "\n",
    "print(\"Finished job on after %s seconds\" % (time.time()-start))\n",
    "faulty_losses = lossHistory.losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(num=None, figsize=(14, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "size = len(healthy_losses+faulty_losses)\n",
    "plt.ylim(0,0.008)\n",
    "ax.plot(range(0,size), healthy_losses+faulty_losses, '-', color='blue', animated = True, linewidth=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
