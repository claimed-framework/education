{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this notebook in IBM Watson Studio (for free), click on the button below and then click on the same button again (top right).\n",
    "\n",
    "In case you need a (free, never expiring, no credit card needed) IBM Cloud account, you can get one here: [ibm.biz/coursera](https://ibm.biz/coursera) (tracked URL)\n",
    "\n",
    "[![](https://github.com/romeokienzler/TensorFlow/raw/master/images/playbutton.png)](https://dataplatform.cloud.ibm.com/analytics/notebooks/v2/d94668e2-3d68-4ee2-bc87-00a885803726/view?access_token=76adb4b998e7cb7bed5e53b0c1a99fb99a0b0a7a24498881e766c094845f0366)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to install TensorFlow 2.x - as of writing of this notebook, there is only an alpha version available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow==1.14.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now just make sure you restart the Kernel so that the changes take effect:\n",
    "\n",
    "![](https://github.com/romeokienzler/TensorFlow/raw/master/images/restart_kernel.png)\n",
    "\n",
    "After the kernel has been restarted, we'll check if we are on TensorFlow 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this worked out. Now it's time to create and run a keras model. Since MNIST is getting boring, let's use the fashion MNIST dataset. If you want to learn more on the data set check out the following links\n",
    "\n",
    "[MNIST](https://en.wikipedia.org/wiki/MNIST_database)  \n",
    "[FashionMNIST](https://github.com/zalandoresearch/fashion-mnist)\n",
    "\n",
    "So in a nutsthell, MNIST contains 60000 28x28 pixel grey scale images of handwritten digits between 0-9 and the corresponding labels. Plus additional 10000 images for testing.\n",
    "\n",
    "Fashing MNIST contains 60000 28x28 pixel grey scale images of fashion articles and the corresponding labels between 0-9. It also contains 10000 test images.\n",
    "\n",
    "Luckyly, this data set is built in to Keras, so let's load it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| Label | Description |\n",
    "| --- | --- |\n",
    "| 0 | T-shirt/top |\n",
    "| 1 | Trouser |\n",
    "| 2 | Pullover |\n",
    "| 3 | Dress |\n",
    "| 4 | Coat |\n",
    "| 5 | Sandal |\n",
    "| 6 | Shirt |\n",
    "| 7 | Sneaker |\n",
    "| 8 | Bag |\n",
    "| 9 | Ankle boot |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f99a512c550>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "i = 10\n",
    "print(train_labels[i])\n",
    "plt.imshow(train_images[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, we get 60000 images of 28 by 28 pixels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels are simply a list of 60000 elements, each one is a number (label) between 0 and 9:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "[9 0 0 ... 3 0 5]\n"
     ]
    }
   ],
   "source": [
    "print(train_labels.shape)\n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at one image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(train_images[0])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this is obviously a shoe :) - Let's normalize the data by making sure every pixel value is between 0..1; this is easy in this case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "\n",
    "test_images = test_images / 255.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For those already familiar with Keras might notice, that mainly only the import statements changed. If you are new to Keras, just check out Week 2 of my DeepLearning course on Coursera, you can get it for free in audit mode: http://coursera.org/learn/ai/. So let's start with ordinary Keras by importing some requirements:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to write our **hello world** softmax regression model, the following code does the job. If you are familiar with Keras, this is really basic stuff. There is only one catch. The following code doesn't run since the latest stable Keras version is incompatible with the alpha release of TensorFlow 2.0. So the following code is for illustration purposes only. Don't run it, it will destroy your hard drive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So from a migration and consistency perspective, it would be nice if we just could change the imports and leave our existing Keras code (which we all love) intact, so let's give it a try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0906 07:20:15.366803 140299157903168 deprecation.py:506] From /opt/conda/envs/Python36/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 10s 161us/sample - loss: 0.5000 - acc: 0.8253 - val_loss: 0.4417 - val_acc: 0.8420\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 10s 159us/sample - loss: 0.3734 - acc: 0.8653 - val_loss: 0.4016 - val_acc: 0.8564\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 9s 155us/sample - loss: 0.3350 - acc: 0.8770 - val_loss: 0.3767 - val_acc: 0.8599\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 9s 153us/sample - loss: 0.3119 - acc: 0.8865 - val_loss: 0.3502 - val_acc: 0.8731\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 9s 154us/sample - loss: 0.2935 - acc: 0.8918 - val_loss: 0.3655 - val_acc: 0.8690\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f99af0d4978>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.nn import relu\n",
    "from tensorflow.nn import softmax\n",
    "\n",
    "\n",
    "    \n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(128, activation=relu),\n",
    "    Dense(10, activation=softmax)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "          loss='sparse_categorical_crossentropy',\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, validation_data=(test_images, test_labels), epochs=5, verbose=1)\n",
    "\n",
    "#model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we didn't change the Keras code at all, but now all imports are coming from the tensorflow package. I felt a bit bad when I've noticed that TensorFlow has eaten up Keras, but in reality, nobody uses a Keras runtime other then TensorFlow anyway, so it doesn't really matter. Just be aware that Keras is Google now and part of TensorFlow. In the next notebook, we'll cover the stategies for parallel training. So stay tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 157s 3ms/sample - loss: 0.5295 - acc: 0.8123 - val_loss: 0.3300 - val_acc: 0.8825\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 157s 3ms/sample - loss: 0.3443 - acc: 0.8775 - val_loss: 0.2869 - val_acc: 0.8953\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 155s 3ms/sample - loss: 0.2925 - acc: 0.8952 - val_loss: 0.2690 - val_acc: 0.9003\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 159s 3ms/sample - loss: 0.2586 - acc: 0.9067 - val_loss: 0.2427 - val_acc: 0.9108\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 158s 3ms/sample - loss: 0.2386 - acc: 0.9126 - val_loss: 0.2314 - val_acc: 0.9150\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 154s 3ms/sample - loss: 0.2173 - acc: 0.9201 - val_loss: 0.2368 - val_acc: 0.9111\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 152s 3ms/sample - loss: 0.1981 - acc: 0.9279 - val_loss: 0.2263 - val_acc: 0.9208\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 155s 3ms/sample - loss: 0.1847 - acc: 0.9320 - val_loss: 0.2250 - val_acc: 0.9186\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 156s 3ms/sample - loss: 0.1722 - acc: 0.9361 - val_loss: 0.2150 - val_acc: 0.9222\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 156s 3ms/sample - loss: 0.1607 - acc: 0.9398 - val_loss: 0.2243 - val_acc: 0.9221\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 152s 3ms/sample - loss: 0.1511 - acc: 0.9441 - val_loss: 0.2155 - val_acc: 0.9273\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 144s 2ms/sample - loss: 0.1400 - acc: 0.9483 - val_loss: 0.2220 - val_acc: 0.9248\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f995c63cd68>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout\n",
    "\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "x_train = train_images\n",
    "x_test = test_images\n",
    "y_train = train_labels\n",
    "y_test = test_labels\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "#model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "        #      optimizer=keras.optimizers.Adadelta(),\n",
    "     #         metrics=['accuracy'])\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "          loss='sparse_categorical_crossentropy',\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
