{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/maxpumperla/dl4j_coursera/releases/download/v0.4/dl4j-snapshot.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/maxpumperla/dl4j_coursera/master/iris.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/fs01/user/se2e-1a118c4f322670-980ba6aaa6c3/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy\n",
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 10\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dataframe = pandas.read_csv(\"iris.txt\", header=None)\n",
    "dataset = dataframe.values\n",
    "X = dataset[:,0:4].astype(float)\n",
    "Y = dataset[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(4, input_dim=4, activation='relu'))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X,dummy_y,epochs=20,batch_size=5)\n",
    "model.save('iris_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some learners constantly reported 502 errors in Watson Studio. \n",
    "#This is due to the limited resources in the free tier and the heavy resource consumption of Keras.\n",
    "#This is a workaround to limit resource consumption\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "K.set_session(K.tf.Session(config=K.tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLF4J: Class path contains multiple SLF4J bindings.\n",
      "SLF4J: Found binding in [jar:file:/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/jars/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/usr/local/src/wml-libs.v18/spark-2.0/jars/ml-event-client-scala-library-0.1.55-201709150512-allinone.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/usr/local/src/wml-libs.v18/spark-2.0/jars/tika-app-2.0-1.14.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/thirdparty/slf4j-simple-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\n",
      "18/03/01 06:27:41 INFO apache.spark.SparkContext: Running Spark version 2.1.2\n",
      "18/03/01 06:27:41 WARN hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "18/03/01 06:27:41 INFO apache.spark.SparkContext: Spark configuration:\n",
      "spark.app.name=DL4J Keras model import runner\n",
      "spark.deploy.resourceScheduler.factory=org.apache.spark.deploy.master.EGOResourceSchedulerFactory\n",
      "spark.driver.maxResultSize=1210M\n",
      "spark.driver.memory=1512M\n",
      "spark.eventLog.dir=/gpfs/fs01/user/se2e-1a118c4f322670-980ba6aaa6c3/events\n",
      "spark.eventLog.enabled=true\n",
      "spark.executor.extraJavaOptions=-Djava.security.egd=file:/dev/./urandom\n",
      "spark.executor.memory=6G\n",
      "spark.extraListeners=com.ibm.spaas.listeners.DB2DialectRegistrar\n",
      "spark.files=file:/gpfs/global_fs01/sym_shared/YPProdSpark/user/se2e-1a118c4f322670-980ba6aaa6c3/notebook/work/iris.txt,file:/gpfs/global_fs01/sym_shared/YPProdSpark/user/se2e-1a118c4f322670-980ba6aaa6c3/notebook/work/iris_model.h5\n",
      "spark.history.fs.logDirectory=/gpfs/fs01/user/se2e-1a118c4f322670-980ba6aaa6c3/events\n",
      "spark.jars=file:/gpfs/global_fs01/sym_shared/YPProdSpark/user/se2e-1a118c4f322670-980ba6aaa6c3/notebook/work/dl4j-snapshot.jar\n",
      "spark.logConf=true\n",
      "spark.master=spark://yp-spark-dal09-env5-0040:7088\n",
      "spark.port.maxRetries=512\n",
      "spark.r.command=/usr/local/src/bluemix_jupyter_bundle.v82/R/bin/Rscript\n",
      "spark.shuffle.service.enabled=true\n",
      "spark.shuffle.service.port=7342\n",
      "spark.sql.ui.retainedExecutions=0\n",
      "spark.submit.deployMode=client\n",
      "spark.task.maxFailures=10\n",
      "spark.ui.enabled=false\n",
      "spark.ui.retainedJobs=0\n",
      "spark.ui.retainedStages=0\n",
      "spark.worker.ui.retainedExecutors=0\n",
      "18/03/01 06:27:41 INFO apache.spark.SecurityManager: Changing view acls to: se2e-1a118c4f322670-980ba6aaa6c3\n",
      "18/03/01 06:27:41 INFO apache.spark.SecurityManager: Changing modify acls to: se2e-1a118c4f322670-980ba6aaa6c3\n",
      "18/03/01 06:27:41 INFO apache.spark.SecurityManager: Changing view acls groups to: \n",
      "18/03/01 06:27:41 INFO apache.spark.SecurityManager: Changing modify acls groups to: \n",
      "18/03/01 06:27:41 INFO apache.spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(se2e-1a118c4f322670-980ba6aaa6c3); groups with view permissions: Set(); users  with modify permissions: Set(se2e-1a118c4f322670-980ba6aaa6c3); groups with modify permissions: Set()\n",
      "18/03/01 06:27:42 INFO spark.util.Utils: Successfully started service 'sparkDriver' on port 41604.\n",
      "18/03/01 06:27:42 INFO apache.spark.SparkEnv: Registering MapOutputTracker\n",
      "18/03/01 06:27:42 INFO apache.spark.SparkEnv: Registering BlockManagerMaster\n",
      "18/03/01 06:27:42 INFO spark.storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
      "18/03/01 06:27:42 INFO spark.storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\n",
      "18/03/01 06:27:42 INFO storage.memory.MemoryStore: MemoryStore started with capacity 727.2 MB\n",
      "18/03/01 06:27:42 INFO apache.spark.SparkEnv: Registering OutputCommitCoordinator\n",
      "18/03/01 06:27:42 INFO apache.spark.SparkContext: Added JAR file:/gpfs/global_fs01/sym_shared/YPProdSpark/user/se2e-1a118c4f322670-980ba6aaa6c3/notebook/work/dl4j-snapshot.jar at spark://10.143.133.25:41604/jars/dl4j-snapshot.jar with timestamp 1519907262566\n",
      "18/03/01 06:27:42 INFO apache.spark.SparkContext: Added file file:/gpfs/global_fs01/sym_shared/YPProdSpark/user/se2e-1a118c4f322670-980ba6aaa6c3/notebook/work/iris.txt at spark://10.143.133.25:41604/files/iris.txt with timestamp 1519907262811\n",
      "18/03/01 06:27:42 INFO spark.util.Utils: Copying /gpfs/global_fs01/sym_shared/YPProdSpark/user/se2e-1a118c4f322670-980ba6aaa6c3/notebook/work/iris.txt to /tmp/spark-21-ego-master/work/spark-73940036-857c-410c-b2a1-3fb962c8e005/userFiles-2cbdcb5c-0353-4787-9a4a-6df418047ac8/iris.txt\n",
      "18/03/01 06:27:42 INFO apache.spark.SparkContext: Added file file:/gpfs/global_fs01/sym_shared/YPProdSpark/user/se2e-1a118c4f322670-980ba6aaa6c3/notebook/work/iris_model.h5 at spark://10.143.133.25:41604/files/iris_model.h5 with timestamp 1519907262827\n",
      "18/03/01 06:27:42 INFO spark.util.Utils: Copying /gpfs/global_fs01/sym_shared/YPProdSpark/user/se2e-1a118c4f322670-980ba6aaa6c3/notebook/work/iris_model.h5 to /tmp/spark-21-ego-master/work/spark-73940036-857c-410c-b2a1-3fb962c8e005/userFiles-2cbdcb5c-0353-4787-9a4a-6df418047ac8/iris_model.h5\n",
      "18/03/01 06:27:42 INFO spark.util.EGOSparkDockerConfig: Executor Container Type is 'normal' from local configuration file.\n",
      "18/03/01 06:27:42 INFO spark.util.EGOSparkDockerConfig: Driver Container Type is 'normal' from local configuration file.\n",
      "18/03/01 06:27:42 INFO spark.util.EGOSparkDockerConfig: spark-ego-docker.conf will not be parsed as docker is not defined as any container type.\n",
      "18/03/01 06:27:42 INFO cluster.ego.EGOFineGrainedSchedulerBackend: setting reserve=0, priority=1, limit=2147483647, gpuLimit=2147483647, master=[Ljava.lang.String;@2c54537c\n",
      "18/03/01 06:27:42 INFO client.ego.EGOAppClient$ClientEndpoint: Connecting to master spark://yp-spark-dal09-env5-0040:7088...\n",
      "18/03/01 06:27:43 INFO network.client.TransportClientFactory: Successfully created connection to yp-spark-dal09-env5-0040/10.143.133.25:7088 after 31 ms (0 ms spent in bootstraps)\n",
      "18/03/01 06:27:43 INFO cluster.ego.EGOFineGrainedSchedulerBackend: Connected to Spark cluster with app ID app-20180301062743-0188-3a0dd109-e85a-4055-bfb9-787b082e668e\n",
      "18/03/01 06:27:43 INFO cluster.ego.EGOFineGrainedSchedulerBackend: Application registered successfully as app-20180301062743-0188-3a0dd109-e85a-4055-bfb9-787b082e668e, executor Container type is normal\n",
      "18/03/01 06:27:43 INFO spark.storage.DiskBlockManager: Init the driver local dir\n",
      "18/03/01 06:27:43 INFO spark.storage.DiskBlockManager: Created local directory at /tmp/spark-21-ego-master/work/blockmgr-927163ed-4386-44e8-b444-97cff68a2852\n",
      "18/03/01 06:27:43 INFO spark.util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34018.\n",
      "18/03/01 06:27:43 INFO network.netty.NettyBlockTransferService: Server created on 10.143.133.25:34018\n",
      "18/03/01 06:27:43 INFO spark.storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n",
      "18/03/01 06:27:43 INFO spark.storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.143.133.25, 34018, None)\n",
      "18/03/01 06:27:43 INFO spark.storage.BlockManagerMasterEndpoint: Registering block manager 10.143.133.25:34018 with 727.2 MB RAM, BlockManagerId(driver, 10.143.133.25, 34018, None)\n",
      "18/03/01 06:27:43 INFO spark.storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.143.133.25, 34018, None)\n",
      "18/03/01 06:27:43 INFO spark.storage.BlockManager: external shuffle service port = 7342\n",
      "18/03/01 06:27:43 INFO spark.storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.143.133.25, 34018, None)\n",
      "18/03/01 06:27:43 INFO jetty.util.log: Logging initialized @5107ms\n",
      "18/03/01 06:27:43 INFO spark.scheduler.EventLoggingListener: Logging events to file:/gpfs/fs01/user/se2e-1a118c4f322670-980ba6aaa6c3/events/app-20180301062743-0188-3a0dd109-e85a-4055-bfb9-787b082e668e\n",
      "18/03/01 06:27:43 INFO apache.spark.SparkContext: Registered listener com.ibm.spaas.listeners.DB2DialectRegistrar\n",
      "18/03/01 06:27:43 INFO cluster.ego.EGODeployScheduler: Spark context initialized.\n",
      "18/03/01 06:27:43 INFO root: application started with appid Some(app-20180301062743-0188-3a0dd109-e85a-4055-bfb9-787b082e668e) and app name DL4J Keras model import runner and application start time is 1519907261053\n",
      "18/03/01 06:27:45 WARN keras.utils.KerasModelUtils: Could not read keras backend used (no backend field found) \n",
      "\n",
      "18/03/01 06:27:45 WARN keras.utils.KerasModelUtils: Unable to match layer parameter name bias:0 for stored weights.\n",
      "18/03/01 06:27:45 INFO linalg.factory.Nd4jBackend: Loaded [CpuBackend] backend\n",
      "18/03/01 06:27:45 WARN org.reflections.Reflections: given scan urls are empty. set urls in the configuration\n",
      "18/03/01 06:27:47 INFO nd4j.nativeblas.NativeOpsHolder: Number of threads used for NativeOps: 12\n",
      "18/03/01 06:27:48 INFO nd4j.nativeblas.Nd4jBlas: Number of threads used for BLAS: 12\n",
      "18/03/01 06:27:48 INFO ops.executioner.DefaultOpExecutioner: Backend used: [CPU]; OS: [Linux]\n",
      "18/03/01 06:27:48 INFO ops.executioner.DefaultOpExecutioner: Cores: [48]; Memory: [1.5GB];\n",
      "18/03/01 06:27:48 INFO ops.executioner.DefaultOpExecutioner: Blas vendor: [OPENBLAS]\n",
      "18/03/01 06:27:49 INFO org.reflections.Reflections: Reflections took 1169 ms to scan 1 urls, producing 495 keys and 2499 values \n",
      "18/03/01 06:27:49 WARN keras.utils.KerasModelUtils: Unable to match layer parameter name kernel:0 for stored weights.\n",
      "18/03/01 06:27:49 WARN keras.utils.KerasModelUtils: Unable to match layer parameter name bias:0 for stored weights.\n",
      "18/03/01 06:27:49 WARN keras.utils.KerasModelUtils: Unable to match layer parameter name kernel:0 for stored weights.\n",
      "18/03/01 06:27:50 WARN modelimport.keras.KerasSequentialModel: Model cannot be trained: output layer dense_2 is not an IOutputLayer (no loss function specified)\n",
      "18/03/01 06:27:51 WARN org.reflections.Reflections: could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/FaspStreamSDK/lib/*. skipping.\n",
      "java.lang.NullPointerException\n",
      "\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:237)\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:204)\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:129)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:507)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:462)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:435)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:122)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1045)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:290)\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasSequentialModel.getMultiLayerConfiguration(KerasSequentialModel.java:203)\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasSequentialModel.getMultiLayerNetwork(KerasSequentialModel.java:223)\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasSequentialModel.getMultiLayerNetwork(KerasSequentialModel.java:213)\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasModelImport.importKerasSequentialModelAndWeights(KerasModelImport.java:143)\n",
      "\tat skymind.dsx.KerasImportCSVSparkRunner.entryPoint(KerasImportCSVSparkRunner.java:102)\n",
      "\tat skymind.dsx.KerasImportCSVSparkRunner.main(KerasImportCSVSparkRunner.java:80)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:507)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n",
      "18/03/01 06:27:51 WARN org.reflections.Reflections: could not create Vfs.Dir from url. ignoring the exception and continuing\n",
      "org.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/FaspStreamSDK/lib/*]\n",
      "either use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:237)\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:204)\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:129)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:507)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:462)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:435)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:122)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1045)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:290)\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasSequentialModel.getMultiLayerConfiguration(KerasSequentialModel.java:203)\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasSequentialModel.getMultiLayerNetwork(KerasSequentialModel.java:223)\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasSequentialModel.getMultiLayerNetwork(KerasSequentialModel.java:213)\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasModelImport.importKerasSequentialModelAndWeights(KerasModelImport.java:143)\n",
      "\tat skymind.dsx.KerasImportCSVSparkRunner.entryPoint(KerasImportCSVSparkRunner.java:102)\n",
      "\tat skymind.dsx.KerasImportCSVSparkRunner.main(KerasImportCSVSparkRunner.java:80)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:507)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n",
      "18/03/01 06:28:19 WARN org.reflections.Reflections: could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/connectors/*/*. skipping.\n",
      "java.lang.NullPointerException\n",
      "\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:237)\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:204)\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:129)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:507)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:462)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:435)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:122)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1045)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:290)\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasSequentialModel.getMultiLayerConfiguration(KerasSequentialModel.java:203)\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasSequentialModel.getMultiLayerNetwork(KerasSequentialModel.java:223)\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasSequentialModel.getMultiLayerNetwork(KerasSequentialModel.java:213)\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasModelImport.importKerasSequentialModelAndWeights(KerasModelImport.java:143)\n",
      "\tat skymind.dsx.KerasImportCSVSparkRunner.entryPoint(KerasImportCSVSparkRunner.java:102)\n",
      "\tat skymind.dsx.KerasImportCSVSparkRunner.main(KerasImportCSVSparkRunner.java:80)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:507)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n",
      "18/03/01 06:28:19 WARN org.reflections.Reflections: could not create Vfs.Dir from url. ignoring the exception and continuing\n",
      "org.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/connectors/*/*]\n",
      "either use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:237)\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:204)\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:129)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:507)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:462)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:435)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:122)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1045)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:290)\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasSequentialModel.getMultiLayerConfiguration(KerasSequentialModel.java:203)\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasSequentialModel.getMultiLayerNetwork(KerasSequentialModel.java:223)\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasSequentialModel.getMultiLayerNetwork(KerasSequentialModel.java:213)\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasModelImport.importKerasSequentialModelAndWeights(KerasModelImport.java:143)\n",
      "\tat skymind.dsx.KerasImportCSVSparkRunner.entryPoint(KerasImportCSVSparkRunner.java:102)\n",
      "\tat skymind.dsx.KerasImportCSVSparkRunner.main(KerasImportCSVSparkRunner.java:80)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:507)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n",
      "18/03/01 06:28:21 WARN org.reflections.Reflections: could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jdbc/lib/*. skipping.\n",
      "java.lang.NullPointerException\n",
      "\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:237)\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:204)\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:129)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:507)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:462)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:435)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:122)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1045)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:290)\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasSequentialModel.getMultiLayerConfiguration(KerasSequentialModel.java:203)\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasSequentialModel.getMultiLayerNetwork(KerasSequentialModel.java:223)\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasSequentialModel.getMultiLayerNetwork(KerasSequentialModel.java:213)\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasModelImport.importKerasSequentialModelAndWeights(KerasModelImport.java:143)\n",
      "\tat skymind.dsx.KerasImportCSVSparkRunner.entryPoint(KerasImportCSVSparkRunner.java:102)\n",
      "\tat skymind.dsx.KerasImportCSVSparkRunner.main(KerasImportCSVSparkRunner.java:80)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:507)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n",
      "18/03/01 06:28:21 WARN org.reflections.Reflections: could not create Vfs.Dir from url. ignoring the exception and continuing\n",
      "org.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jdbc/lib/*]\n",
      "either use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:237)\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:204)\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:129)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:507)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:462)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:435)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:122)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1045)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:290)\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasSequentialModel.getMultiLayerConfiguration(KerasSequentialModel.java:203)\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasSequentialModel.getMultiLayerNetwork(KerasSequentialModel.java:223)\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasSequentialModel.getMultiLayerNetwork(KerasSequentialModel.java:213)\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasModelImport.importKerasSequentialModelAndWeights(KerasModelImport.java:143)\n",
      "\tat skymind.dsx.KerasImportCSVSparkRunner.entryPoint(KerasImportCSVSparkRunner.java:102)\n",
      "\tat skymind.dsx.KerasImportCSVSparkRunner.main(KerasImportCSVSparkRunner.java:80)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:507)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n",
      "18/03/01 06:28:25 WARN org.reflections.Reflections: could not create Dir using directory from url file:/gpfs/global_fs01/sym_shared/YPProdSpark/user/se2e-1a118c4f322670-980ba6aaa6c3/data/libs/scala-2.11/*. skipping.\n",
      "java.lang.NullPointerException\n",
      "\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:237)\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:204)\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:129)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:507)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:462)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:435)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:122)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1045)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:290)\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasSequentialModel.getMultiLayerConfiguration(KerasSequentialModel.java:203)\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasSequentialModel.getMultiLayerNetwork(KerasSequentialModel.java:223)\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasSequentialModel.getMultiLayerNetwork(KerasSequentialModel.java:213)\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasModelImport.importKerasSequentialModelAndWeights(KerasModelImport.java:143)\n",
      "\tat skymind.dsx.KerasImportCSVSparkRunner.entryPoint(KerasImportCSVSparkRunner.java:102)\n",
      "\tat skymind.dsx.KerasImportCSVSparkRunner.main(KerasImportCSVSparkRunner.java:80)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:507)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n",
      "18/03/01 06:28:25 WARN org.reflections.Reflections: could not create Vfs.Dir from url. ignoring the exception and continuing\n",
      "org.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/gpfs/global_fs01/sym_shared/YPProdSpark/user/se2e-1a118c4f322670-980ba6aaa6c3/data/libs/scala-2.11/*]\n",
      "either use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:237)\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:204)\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:129)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:507)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:462)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:435)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:122)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1045)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:290)\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasSequentialModel.getMultiLayerConfiguration(KerasSequentialModel.java:203)\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasSequentialModel.getMultiLayerNetwork(KerasSequentialModel.java:223)\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasSequentialModel.getMultiLayerNetwork(KerasSequentialModel.java:213)\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasModelImport.importKerasSequentialModelAndWeights(KerasModelImport.java:143)\n",
      "\tat skymind.dsx.KerasImportCSVSparkRunner.entryPoint(KerasImportCSVSparkRunner.java:102)\n",
      "\tat skymind.dsx.KerasImportCSVSparkRunner.main(KerasImportCSVSparkRunner.java:80)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:507)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n",
      "18/03/01 06:28:28 WARN org.reflections.Reflections: could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/ASBServer/apps/lib/iis/*/*. skipping.\r\n",
      "java.lang.NullPointerException\r\n",
      "\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:507)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:462)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:435)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:122)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1045)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:290)\r\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasSequentialModel.getMultiLayerConfiguration(KerasSequentialModel.java:203)\r\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasSequentialModel.getMultiLayerNetwork(KerasSequentialModel.java:223)\r\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasSequentialModel.getMultiLayerNetwork(KerasSequentialModel.java:213)\r\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasModelImport.importKerasSequentialModelAndWeights(KerasModelImport.java:143)\r\n",
      "\tat skymind.dsx.KerasImportCSVSparkRunner.entryPoint(KerasImportCSVSparkRunner.java:102)\r\n",
      "\tat skymind.dsx.KerasImportCSVSparkRunner.main(KerasImportCSVSparkRunner.java:80)\r\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n",
      "18/03/01 06:28:28 WARN org.reflections.Reflections: could not create Vfs.Dir from url. ignoring the exception and continuing\r\n",
      "org.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/ASBServer/apps/lib/iis/*/*]\r\n",
      "either use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:507)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:462)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:435)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:122)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1045)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:290)\r\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasSequentialModel.getMultiLayerConfiguration(KerasSequentialModel.java:203)\r\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasSequentialModel.getMultiLayerNetwork(KerasSequentialModel.java:223)\r\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasSequentialModel.getMultiLayerNetwork(KerasSequentialModel.java:213)\r\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasModelImport.importKerasSequentialModelAndWeights(KerasModelImport.java:143)\r\n",
      "\tat skymind.dsx.KerasImportCSVSparkRunner.entryPoint(KerasImportCSVSparkRunner.java:102)\r\n",
      "\tat skymind.dsx.KerasImportCSVSparkRunner.main(KerasImportCSVSparkRunner.java:80)\r\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n",
      "18/03/01 06:28:28 WARN org.reflections.Reflections: could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jars/JISPlugins/*. skipping.\r\n",
      "java.lang.NullPointerException\r\n",
      "\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:507)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:462)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:435)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:122)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1045)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:290)\r\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasSequentialModel.getMultiLayerConfiguration(KerasSequentialModel.java:203)\r\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasSequentialModel.getMultiLayerNetwork(KerasSequentialModel.java:223)\r\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasSequentialModel.getMultiLayerNetwork(KerasSequentialModel.java:213)\r\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasModelImport.importKerasSequentialModelAndWeights(KerasModelImport.java:143)\r\n",
      "\tat skymind.dsx.KerasImportCSVSparkRunner.entryPoint(KerasImportCSVSparkRunner.java:102)\r\n",
      "\tat skymind.dsx.KerasImportCSVSparkRunner.main(KerasImportCSVSparkRunner.java:80)\r\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n",
      "18/03/01 06:28:28 WARN org.reflections.Reflections: could not create Vfs.Dir from url. ignoring the exception and continuing\r\n",
      "org.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jars/JISPlugins/*]\r\n",
      "either use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:507)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:462)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:435)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:122)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1045)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:290)\r\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasSequentialModel.getMultiLayerConfiguration(KerasSequentialModel.java:203)\r\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasSequentialModel.getMultiLayerNetwork(KerasSequentialModel.java:223)\r\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasSequentialModel.getMultiLayerNetwork(KerasSequentialModel.java:213)\r\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasModelImport.importKerasSequentialModelAndWeights(KerasModelImport.java:143)\r\n",
      "\tat skymind.dsx.KerasImportCSVSparkRunner.entryPoint(KerasImportCSVSparkRunner.java:102)\r\n",
      "\tat skymind.dsx.KerasImportCSVSparkRunner.main(KerasImportCSVSparkRunner.java:80)\r\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n",
      "18/03/01 06:28:30 WARN org.reflections.Reflections: could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/branded_jdbc/lib/*. skipping.\n",
      "java.lang.NullPointerException\n",
      "\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:237)\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:204)\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:129)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:507)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:462)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:435)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:122)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1045)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:290)\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasSequentialModel.getMultiLayerConfiguration(KerasSequentialModel.java:203)\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasSequentialModel.getMultiLayerNetwork(KerasSequentialModel.java:223)\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasSequentialModel.getMultiLayerNetwork(KerasSequentialModel.java:213)\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasModelImport.importKerasSequentialModelAndWeights(KerasModelImport.java:143)\n",
      "\tat skymind.dsx.KerasImportCSVSparkRunner.entryPoint(KerasImportCSVSparkRunner.java:102)\n",
      "\tat skymind.dsx.KerasImportCSVSparkRunner.main(KerasImportCSVSparkRunner.java:80)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:507)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n",
      "18/03/01 06:28:30 WARN org.reflections.Reflections: could not create Vfs.Dir from url. ignoring the exception and continuing\n",
      "org.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/branded_jdbc/lib/*]\n",
      "either use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:237)\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:204)\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:129)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:507)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:462)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:435)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:122)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1045)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:290)\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasSequentialModel.getMultiLayerConfiguration(KerasSequentialModel.java:203)\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasSequentialModel.getMultiLayerNetwork(KerasSequentialModel.java:223)\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasSequentialModel.getMultiLayerNetwork(KerasSequentialModel.java:213)\n",
      "\tat org.deeplearning4j.nn.modelimport.keras.KerasModelImport.importKerasSequentialModelAndWeights(KerasModelImport.java:143)\n",
      "\tat skymind.dsx.KerasImportCSVSparkRunner.entryPoint(KerasImportCSVSparkRunner.java:102)\n",
      "\tat skymind.dsx.KerasImportCSVSparkRunner.main(KerasImportCSVSparkRunner.java:80)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:507)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n",
      "18/03/01 06:28:32 INFO org.reflections.Reflections: Reflections took 42754 ms to scan 442 urls, producing 14188 keys and 100916 values \n",
      "18/03/01 06:28:33 INFO nn.multilayer.MultiLayerNetwork: Starting MultiLayerNetwork with WorkspaceModes set to [training: NONE; inference: SEPARATE]\n",
      "Exception in thread \"main\" java.lang.IllegalArgumentException: No such file or directory: /gpfs/global_fs01/sym_shared/YPProdSpark/user/se2e-1a118c4f322670-980ba6aaa6c3/notebook/work/data.csv\n",
      "\tat org.datavec.api.split.FileSplit.initialize(FileSplit.java:95)\n",
      "\tat org.datavec.api.split.FileSplit.<init>(FileSplit.java:62)\n",
      "\tat org.datavec.api.split.FileSplit.<init>(FileSplit.java:66)\n",
      "\tat skymind.dsx.KerasImportCSVSparkRunner.entryPoint(KerasImportCSVSparkRunner.java:119)\n",
      "\tat skymind.dsx.KerasImportCSVSparkRunner.main(KerasImportCSVSparkRunner.java:80)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:507)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n",
      "18/03/01 06:28:33 INFO apache.spark.SparkContext: Invoking stop() from shutdown hook\n",
      "18/03/01 06:28:33 INFO cluster.ego.EGOFineGrainedSchedulerBackend: hosts Set() need to delete the cache data for application[%s] app-20180301062743-0188-3a0dd109-e85a-4055-bfb9-787b082e668e\n",
      "18/03/01 06:28:33 INFO cluster.ego.EGOFineGrainedSchedulerBackend: Waiting for rpc request receive the response.\n",
      "18/03/01 06:28:33 INFO cluster.ego.EGODeployScheduler: Spark context stopped.\n",
      "18/03/01 06:28:33 INFO apache.spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!\n",
      "18/03/01 06:28:33 INFO storage.memory.MemoryStore: MemoryStore cleared\n",
      "18/03/01 06:28:33 INFO spark.storage.BlockManager: BlockManager stopped\n",
      "18/03/01 06:28:33 INFO spark.storage.BlockManagerMaster: BlockManagerMaster stopped\n",
      "18/03/01 06:28:33 INFO spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!\n",
      "18/03/01 06:28:33 INFO apache.spark.SparkContext: Successfully stopped SparkContext\n",
      "18/03/01 06:28:33 INFO spark.util.ShutdownHookManager: Shutdown hook called\n",
      "18/03/01 06:28:33 INFO spark.util.ShutdownHookManager: Deleting directory /tmp/spark-21-ego-master/work/spark-73940036-857c-410c-b2a1-3fb962c8e005\n"
     ]
    }
   ],
   "source": [
    "!$SPARK_HOME/bin/spark-submit \\\n",
    "--class skymind.dsx.KerasImportCSVSparkRunner \\\n",
    "--files iris.txt,iris_model.h5 \\\n",
    "--master $MASTER \\\n",
    "dl4j-snapshot.jar \\\n",
    "-batchSizePerWorker 15 \\\n",
    "-indexLabel 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv dl4j-snapshot.jar.1 dl4-snapshot.jar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dl4j-snapshot.jar\r\n"
     ]
    }
   ],
   "source": [
    "!ls dl4j-snapshot.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 with Spark 2.1",
   "language": "python",
   "name": "python2-spark21"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
