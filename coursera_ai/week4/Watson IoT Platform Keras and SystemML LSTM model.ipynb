{"nbformat_minor": 1, "cells": [{"source": "import numpy as np\nfrom numpy import concatenate\nfrom matplotlib import pyplot\nfrom pandas import read_csv\nfrom pandas import DataFrame\nfrom pandas import concat\nimport sklearn\nimport keras, math\nfrom  sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import mean_squared_error\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.callbacks import Callback\nfrom keras.models import Sequential\nfrom keras.layers import LSTM, Dense, Activation\nimport pickle\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom Queue import Queue\n%matplotlib inline", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stderr", "text": "Using TensorFlow backend.\n/gpfs/fs01/user/s745-af92d31e43ed70-980ba6aaa6c3/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n  from ._conv import register_converters as _register_converters\n"}], "execution_count": 1}, {"source": "data_healthy = pickle.load(open('watsoniotp.healthy.pickle', 'rb'))\ndata_broken = pickle.load(open('watsoniotp.broken.pickle', 'rb'))", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 2}, {"source": "data_healthy = data_healthy.reshape(3000,3)\ndata_broken = data_broken.reshape(3000,3)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 3}, {"source": "def scaleData(data):\n    # normalize features\n    scaler = MinMaxScaler(feature_range=(0, 1))\n    return scaler.fit_transform(data)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 4}, {"source": "data_healthy_scaled = scaleData(data_healthy)\ndata_broken_scaled = scaleData(data_broken)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 5}, {"source": "timesteps = 10\ndim = 3\nsamples = 300\ndata_healthy_scaled_reshaped = data_healthy_scaled", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 6}, {"source": "# design network\n\nmodel = Sequential()\nmodel.add(LSTM(50,input_shape=(timesteps,dim),return_sequences=False))\nmodel.add(Dense(timesteps*dim))\nmodel.compile(loss='mse', optimizer=keras.optimizers.SGD(lr=0.01, momentum=0.95, decay=5e-4, nesterov=True))", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 8}, {"source": "## Now use Keras2DML importer", "cell_type": "markdown", "metadata": {}}, {"source": "from systemml.mllearn import Keras2DML\nepochs = 50\nbatch_size = 50\nmax_iter = int(epochs*math.ceil(samples/batch_size))\nmodel = Keras2DML(spark, model, input_shape=(timesteps, dim, 1), batch_size=batch_size, max_iter=max_iter, test_interval=0, display=10)\nmodel.set(perform_one_hot_encoding=False)\nmodel.set(debug=True) ", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Loading the model from /gpfs/fs01/user/s745-af92d31e43ed70-980ba6aaa6c3/notebook/tmp/tmp_flUKW...\nSystemML Statistics:\nTotal execution time:\t\t0.000 sec.\nNumber of executed Spark inst:\t0.\n\n\n"}, {"output_type": "execute_result", "data": {"text/plain": "Caffe2DML"}, "execution_count": 10, "metadata": {}}], "execution_count": 10}, {"source": "def train(data):\n    data = data.reshape(samples, timesteps*dim)\n    model.fit(data, data) # epochs=50, batch_size=72, validation_data=(data, data), verbose=0, shuffle=False,callbacks=[LossHistory()])", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 12}, {"source": "train(data_healthy_scaled)", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Time taken to generate training script from Caffe proto: 0.070278461 seconds.\n001|debug = TRUE\n002|source(\"nn/layers/lstm.dml\") as lstm\n003|source(\"nn/layers/affine.dml\") as affine\n004|source(\"nn/layers/l2_loss.dml\") as l2_loss\n005|source(\"nn/optim/sgd_nesterov.dml\") as sgd_nesterov\n006|source(\"nn/layers/l1_reg.dml\") as l1_reg\n007|source(\"nn/layers/l2_reg.dml\") as l2_reg\n008|X_full_path = ifdef($X, \" \")\n009|X_full = read(X_full_path)\n010|y_full_path = ifdef($y, \" \")\n011|y_full = read(y_full_path)\n012|num_images = nrow(y_full)\n013|weights = ifdef($weights, \" \")\n014|# Initialize the layers and solvers\n015|BATCH_SIZE = 50\n016|[lstm_1_weight,lstm_1_bias,out0_3,cellState0_3] = lstm::init(BATCH_SIZE,3,50)\n017|dcellState0_3 = matrix(0, rows=BATCH_SIZE, cols=50)\n018|[dense_1_weight,dense_1_bias] = affine::init(50,30)\n019|# Load the weights. Note: keeping the initialization code in case the layer wants to initialize non-weights and non-bias\n020|lstm_1_weight = read(weights + \"/lstm_1_weight.mtx\")\n021|dense_1_weight = read(weights + \"/dense_1_weight.mtx\")\n022|lstm_1_bias = read(weights + \"/lstm_1_bias.mtx\")\n023|dense_1_bias = read(weights + \"/dense_1_bias.mtx\")\n024|lstm_1_weight_v = sgd_nesterov::init(lstm_1_weight)\n025|lstm_1_bias_v = sgd_nesterov::init(lstm_1_bias)\n026|dense_1_weight_v = sgd_nesterov::init(dense_1_weight)\n027|dense_1_bias_v = sgd_nesterov::init(dense_1_bias)\n028|X = X_full\n029|y = y_full\n030|num_images = nrow(y)\n031|num_iters_per_epoch = ceil(num_images / BATCH_SIZE)\n032|lr = 0.01\n033|max_iter = ifdef($max_iter, 300)\n034|e = 0\n035|for(iter in 1:max_iter) {\n036|\tbeg = ((iter-1) * BATCH_SIZE) %% num_images + 1; end = min(beg + BATCH_SIZE - 1, num_images); Xb = X[beg:end,]; yb = y[beg:end,]; \n037|\t# Perform forward pass\n038|\t\t\n039|if( 10*3 != ncol(Xb)) {\n040|\tstop(\"Incorrect number of columns for Xb in lstm() script. Expected:\" + 10*3 + \" but found \" +  ncol(Xb) )\n041|}\n042|\n043|if( 50 != ncol(out0_3)) {\n044|\tstop(\"Incorrect number of columns for out0_3 in lstm() script. Expected:\" + 50 + \" but found \" +  ncol(out0_3) )\n045|}\n046|\n047|if( 50 != ncol(cellState0_3)) {\n048|\tstop(\"Incorrect number of columns for cellState0_3 in lstm() script. Expected:\" + 50 + \" but found \" +  ncol(cellState0_3) )\n049|}\n050|\n051|if( 3+50 != nrow(lstm_1_weight)) {\n052|\tstop(\"Incorrect number of rows for lstm_1_weight in lstm() script. Expected:\" + 3+50 + \" but found \" +  nrow(lstm_1_weight) )\n053|}\n054|\n055|if( 4*50 != ncol(lstm_1_weight)) {\n056|\tstop(\"Incorrect number of columns for lstm_1_weight in lstm() script. Expected:\" + 4*50 + \" but found \" +  ncol(lstm_1_weight) )\n057|}\n058|\n059|if( 1 != nrow(lstm_1_bias)) {\n060|\tstop(\"Incorrect number of rows for lstm_1_bias in lstm() script. Expected:\" + 1 + \" but found \" +  nrow(lstm_1_bias) )\n061|}\n062|\n063|if( 4*50 != ncol(lstm_1_bias)) {\n064|\tstop(\"Incorrect number of columns for lstm_1_bias in lstm() script. Expected:\" + 4*50 + \" but found \" +  ncol(lstm_1_bias) )\n065|}\n066|[out3,cellState_3,cache_out_3,cache_c_3,cache_ifog_3] = lstm::forward(Xb,lstm_1_weight,lstm_1_bias,10,3,FALSE,out0_3,cellState0_3)\n067|\n068|if( 50 != ncol(out3)) {\n069|\tstop(\"Incorrect number of columns for out3 in lstm() script. Expected:\" + 50 + \" but found \" +  ncol(out3) )\n070|}\n071|\t\n072|if( 50 != ncol(out3)) {\n073|\tstop(\"Incorrect number of columns for out3 in affine() script. Expected:\" + 50 + \" but found \" +  ncol(out3) )\n074|}\n075|\n076|if( 50 != nrow(dense_1_weight)) {\n077|\tstop(\"Incorrect number of rows for dense_1_weight in affine(forward) script. Expected:\" + 50 + \" but found \" +  nrow(dense_1_weight) )\n078|}\n079|\n080|if( 30 != ncol(dense_1_weight)) {\n081|\tstop(\"Incorrect number of columns for dense_1_weight in affine(forward) script. Expected:\" + 30 + \" but found \" +  ncol(dense_1_weight) )\n082|}\n083|\n084|if( 1 != nrow(dense_1_bias)) {\n085|\tstop(\"Incorrect number of rows for dense_1_bias in affine() script. Expected:\" + 1 + \" but found \" +  nrow(dense_1_bias) )\n086|}\n087|\n088|if( 30 != ncol(dense_1_bias)) {\n089|\tstop(\"Incorrect number of columns for dense_1_bias in affine() script. Expected:\" + 30 + \" but found \" +  ncol(dense_1_bias) )\n090|}\n091|out4 = affine::forward(out3,dense_1_weight,dense_1_bias)\n092|\tout5 = out4\n093|\t# Perform backward pass\n094|\tout5 = l2_loss::forward(out4,yb)\n095|dOut5 = l2_loss::backward(out4,yb); dOut5_4 = dOut5; dOut5_2 = dOut5; \n096|\t\n097|if( 30 != ncol(dOut5_4)) {\n098|\tstop(\"Incorrect number of columns for dOut5_4 in affine() script. Expected:\" + 30 + \" but found \" +  ncol(dOut5_4) )\n099|}\n100|\n101|if( 50 != ncol(out3)) {\n102|\tstop(\"Incorrect number of columns for out3 in affine() script. Expected:\" + 50 + \" but found \" +  ncol(out3) )\n103|}\n104|\n105|if( 50 != nrow(dense_1_weight)) {\n106|\tstop(\"Incorrect number of rows for dense_1_weight in affine(backward) script. Expected:\" + 50 + \" but found \" +  nrow(dense_1_weight) )\n107|}\n108|\n109|if( 30 != ncol(dense_1_weight)) {\n110|\tstop(\"Incorrect number of columns for dense_1_weight in affine(backward) script. Expected:\" + 30 + \" but found \" +  ncol(dense_1_weight) )\n111|}\n112|\n113|if( 1 != nrow(dense_1_bias)) {\n114|\tstop(\"Incorrect number of rows for dense_1_bias in affine() script. Expected:\" + 1 + \" but found \" +  nrow(dense_1_bias) )\n115|}\n116|\n117|if( 30 != ncol(dense_1_bias)) {\n118|\tstop(\"Incorrect number of columns for dense_1_bias in affine() script. Expected:\" + 30 + \" but found \" +  ncol(dense_1_bias) )\n119|}\n120|[dOut4,dense_1_dWeight,dense_1_dBias] = affine::backward(dOut5_4,out3,dense_1_weight,dense_1_bias); dOut4_3 = dOut4; \n121|\t\n122|if( 50 != ncol(dOut4_3)) {\n123|\tstop(\"Incorrect number of columns for dOut4_3 in lstm() script. Expected:\" + 50 + \" but found \" +  ncol(dOut4_3) )\n124|}\n125|\n126|if( 50 != ncol(dcellState0_3)) {\n127|\tstop(\"Incorrect number of columns for dcellState0_3 in lstm() script. Expected:\" + 50 + \" but found \" +  ncol(dcellState0_3) )\n128|}\n129|\n130|if( 10*3 != ncol(Xb)) {\n131|\tstop(\"Incorrect number of columns for Xb in lstm() script. Expected:\" + 10*3 + \" but found \" +  ncol(Xb) )\n132|}\n133|\n134|if( 50 != ncol(out0_3)) {\n135|\tstop(\"Incorrect number of columns for out0_3 in lstm() script. Expected:\" + 50 + \" but found \" +  ncol(out0_3) )\n136|}\n137|\n138|if( 50 != ncol(cellState0_3)) {\n139|\tstop(\"Incorrect number of columns for cellState0_3 in lstm() script. Expected:\" + 50 + \" but found \" +  ncol(cellState0_3) )\n140|}\n141|\n142|if( 10 != nrow(cache_out_3)) {\n143|\tstop(\"Incorrect number of rows for cache_out_3 in lstm() script. Expected:\" + 10 + \" but found \" +  nrow(cache_out_3) )\n144|}\n145|\n146|if( 10 != nrow(cache_c_3)) {\n147|\tstop(\"Incorrect number of rows for cache_c_3 in lstm() script. Expected:\" + 10 + \" but found \" +  nrow(cache_c_3) )\n148|}\n149|\n150|if( 10 != nrow(cache_ifog_3)) {\n151|\tstop(\"Incorrect number of rows for cache_ifog_3 in lstm() script. Expected:\" + 10 + \" but found \" +  nrow(cache_ifog_3) )\n152|}\n153|\n154|if( 3+50 != nrow(lstm_1_weight)) {\n155|\tstop(\"Incorrect number of rows for lstm_1_weight in lstm() script. Expected:\" + 3+50 + \" but found \" +  nrow(lstm_1_weight) )\n156|}\n157|\n158|if( 4*50 != ncol(lstm_1_weight)) {\n159|\tstop(\"Incorrect number of columns for lstm_1_weight in lstm() script. Expected:\" + 4*50 + \" but found \" +  ncol(lstm_1_weight) )\n160|}\n161|\n162|if( 1 != nrow(lstm_1_bias)) {\n163|\tstop(\"Incorrect number of rows for lstm_1_bias in lstm() script. Expected:\" + 1 + \" but found \" +  nrow(lstm_1_bias) )\n164|}\n165|\n166|if( 4*50 != ncol(lstm_1_bias)) {\n167|\tstop(\"Incorrect number of columns for lstm_1_bias in lstm() script. Expected:\" + 4*50 + \" but found \" +  ncol(lstm_1_bias) )\n168|}\n169|[dOut3,lstm_1_dWeight,lstm_1_dBias,dout0_3,dcellState0_3] = lstm::backward(dOut4_3,dcellState0_3,Xb,lstm_1_weight,lstm_1_bias,10,3,FALSE,out0_3,cellState0_3,cache_out_3,cache_c_3,cache_ifog_3); dOut3_2 = dOut3; \n170|\t\t# Update the parameters\n171|\t\t\tlstm_1_dWeight_reg = l2_reg::backward(lstm_1_weight, 5.000000237487257E-4)\n172|\tlstm_1_dWeight = lstm_1_dWeight + lstm_1_dWeight_reg\n173|\t[lstm_1_weight,lstm_1_weight_v] = sgd_nesterov::update(lstm_1_weight,lstm_1_dWeight,lr,0.949999988079071,lstm_1_weight_v)\n174|\t[lstm_1_bias,lstm_1_bias_v] = sgd_nesterov::update(lstm_1_bias,lstm_1_dBias,lr,0.949999988079071,lstm_1_bias_v)\n175|\t\tdense_1_dWeight_reg = l2_reg::backward(dense_1_weight, 5.000000237487257E-4)\n176|\tdense_1_dWeight = dense_1_dWeight + dense_1_dWeight_reg\n177|\t[dense_1_weight,dense_1_weight_v] = sgd_nesterov::update(dense_1_weight,dense_1_dWeight,lr,0.949999988079071,dense_1_weight_v)\n178|\t[dense_1_bias,dense_1_bias_v] = sgd_nesterov::update(dense_1_bias,dense_1_dBias,lr,0.949999988079071,dense_1_bias_v)\n179|\t\t# Compute training loss & accuracy\n180|\tif(iter  %% 10 == 0) {\n181|\t\tloss = 0\n182|\t\taccuracy = 0\n183|tmp_loss = l2_loss::forward(out4,yb)\n184|\t\tloss = loss + tmp_loss\n185|\t\taccuracy = -1\n186|\t\ttraining_loss = loss\n187|\t\ttraining_accuracy = accuracy\n188|\t\tprint(\"Iter:\" + iter + \", training loss:\" + training_loss + \", training accuracy:\" + training_accuracy)\n189|\t}\n190|\tif(iter %% num_iters_per_epoch == 0) {\n191|\t\te = e + 1\n192|\t\t# Learning rate\n193|\t\tlr = (0.009999999776482582 * 5.000000237487257E-4 ^  floor(e/100000.0))\n194|\t}\n195|}\n"}, {"output_type": "stream", "name": "stdout", "text": "Iter:10, training loss:0.7402424226463188, training accuracy:-1\nIter:20, training loss:0.6137985615946043, training accuracy:-1\nIter:30, training loss:0.4943419402874561, training accuracy:-1\nIter:40, training loss:0.3505907102308653, training accuracy:-1\nIter:50, training loss:0.2015497779921026, training accuracy:-1\nIter:60, training loss:0.1807776464306712, training accuracy:-1\nIter:70, training loss:0.15491052753286896, training accuracy:-1\nIter:80, training loss:0.0906057371240747, training accuracy:-1\nIter:90, training loss:0.08331339644063858, training accuracy:-1\nIter:100, training loss:0.06279892274114533, training accuracy:-1\nIter:110, training loss:0.04359085517807979, training accuracy:-1\nIter:120, training loss:0.04592381152112904, training accuracy:-1\nIter:130, training loss:0.04074779926981933, training accuracy:-1\nIter:140, training loss:0.032874132064213066, training accuracy:-1\nIter:150, training loss:0.0339012386421331, training accuracy:-1\nIter:160, training loss:0.03249200136805042, training accuracy:-1\nIter:170, training loss:0.028435508288770034, training accuracy:-1\nIter:180, training loss:0.028980053400157413, training accuracy:-1\nIter:190, training loss:0.0279550336635065, training accuracy:-1\nIter:200, training loss:0.02448781565146785, training accuracy:-1\nIter:210, training loss:0.02471286213389626, training accuracy:-1\nIter:220, training loss:0.02380919689671781, training accuracy:-1\nIter:230, training loss:0.020762684962419956, training accuracy:-1\nIter:240, training loss:0.0205427644965333, training accuracy:-1\nIter:250, training loss:0.01987681529049726, training accuracy:-1\nIter:260, training loss:0.017282360487820198, training accuracy:-1\nIter:270, training loss:0.01674913913702608, training accuracy:-1\nIter:280, training loss:0.01631841580354368, training accuracy:-1\nIter:290, training loss:0.014165282887508974, training accuracy:-1\nIter:300, training loss:0.013537587748425693, training accuracy:-1\nSystemML Statistics:\nTotal execution time:\t\t30.574 sec.\nNumber of executed Spark inst:\t2.\n\n\n"}], "execution_count": 13}, {"source": "", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}], "metadata": {"kernelspec": {"display_name": "Python 2 with Spark 2.1", "name": "python2-spark21", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "2.7.11", "name": "python", "pygments_lexer": "ipython2", "file_extension": ".py", "codemirror_mode": {"version": 2, "name": "ipython"}}}, "nbformat": 4}